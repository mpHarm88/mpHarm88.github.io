---

layout: post
title: ðŸ”Ž Exploring Black Box Classification Models using Google Analytics Data
subtitle: Use my dashboard to make real time predictions.
bigimg: img/black_box.jpg
image: img/black_box.jpg, img/randomforest.png, img/xgbclassifier.png, img/xgbshap.png, img/rfshap.png
tags: [xgboost, pandas, scikit-learn, eli5, shap, pdpbox, category-encoders, numpy]

---

#### ðŸ”®Try making your own predictions using the dashboard [here](https://cust-pred.herokuapp.com)!
One of the trade-offs that come with using black-box models includes losing model interpretability. Fortunately, with the help of the confusion matrix and Shapley's summary plots, there are ways of interpreting these complicated models. 

I created two models, one using [XGBoosts XGBClassifier()](https://xgboost.readthedocs.io/en/latest/) and the other using [Scikit-Learns RandomForestClassifier()](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) to compare and try to interpret how both models came to the same answer differently. The data comes from google analytics and uses standard features associated with the google analytics platform. This target of the data was the "Revenue" columns, which showed a True or False for whether or not the customer bought something on the site. 



### Results

|Classifier    |Accuracy|ROC/AUC|
|:------------:|:------:|:-----:|
|XGBoost       |   90.1%|  92.5%|
|Random Forest |   90.7%|  90.1%|

### Confusion Matrix (Revenue=1, No Revenue=0)

<div align="center">
  <img src="/img/xgbclassifier.png"><img src="/img/randomforest.png">
</div>

### Shapley Values
How did the models correctly predict the same prediction differently?

<h4 align="center">XGBClassifier</h4>

<div align="center">
  <img src="/img/xgbshap.png">
</div>

<h4 align="center">Random Forest</h4>

<div align="center">
  <img src="/img/rfshap.png">
</div>

